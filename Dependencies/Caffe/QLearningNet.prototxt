name: "QLearningNet"
layer {
	name: "input"
	type: "MemoryData"
	memory_data_param {
		batch_size: 8
		channels: 1
		height: 1
		width: 4
	}
	top: "input"
	top: "label"
}

layer {
	name: "ip0"
	type: "InnerProduct"
	# learning rate and decay multipliers for the weights
	param { 
		lr_mult: 1 
		decay_mult: 1 
	}
	# learning rate and decay multipliers for the biases
	param { 
		lr_mult: 2 
		decay_mult: 0 
	}
	inner_product_param {
		num_output: 128
		weight_filler {
		  type: "gaussian"
		  std: 0.01
		}
		bias_filler {
		  type: "constant"
		  value: 0
		}
	}
	bottom: "input"
	top: "ip0"
}

layer {
	name: "relu0"
	type: "ReLU"
	bottom: "ip0"
	top: "relu0"
}

layer {
	name: "ip1"
	type: "InnerProduct"
	# learning rate and decay multipliers for the weights
	param { 
		lr_mult: 1 
		decay_mult: 1 }
	# learning rate and decay multipliers for the biases
	param { 
		lr_mult: 2 
		decay_mult: 0 
	}
	inner_product_param {
		num_output: 128
		weight_filler {
		  type: "gaussian"
		  std: 0.01
		}
		bias_filler {
		  type: "constant"
		  value: 0
		}
	}
	bottom: "relu0"
	top: "ip1"
}

layer {
	name: "relu1"
	type: "ReLU"
	bottom: "ip1"
	top: "relu1"
}

layer {
	name: "out"
	type: "InnerProduct"
	# learning rate and decay multipliers for the weights
	param { 
		lr_mult: 1 
		decay_mult: 1 
	}
	# learning rate and decay multipliers for the biases
	param { 
		lr_mult: 2 
		decay_mult: 0 
	}
	inner_product_param {
		num_output: 4
		weight_filler {
		  type: "gaussian"
		  std: 0.01
		}
		bias_filler {
		  type: "constant"
		  value: 0
		}
	}
	bottom: "outHidden2"
	top: "out"
}

layer {
	name: "loss"
	type: "EuclideanLoss"
	bottom: "out"
	top: "loss"
}

